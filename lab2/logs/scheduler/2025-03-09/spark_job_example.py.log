[2025-03-09T12:26:08.364+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:08.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:26:08.366+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:08.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:08.373+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:08.371+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job_example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_example.py", line 33, in <module>
    spark_job = SparkSubmitOperator(task_id='Spark Task: 0',
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'Spark Task: 0' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-09T12:26:08.373+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:08.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.020 seconds
[2025-03-09T12:26:38.630+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:38.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:26:38.635+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:38.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:38.645+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:38.643+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job_example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_example.py", line 33, in <module>
    spark_job = SparkSubmitOperator(task_id='Spark Task: 0',
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'Spark Task: 0' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-09T12:26:38.645+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:38.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.038 seconds
[2025-03-09T12:26:41.670+0000] {processor.py:186} INFO - Started process (PID=197) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:41.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:26:41.674+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:41.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:41.682+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:41.680+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job_example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_example.py", line 33, in <module>
    spark_job = SparkSubmitOperator(task_id='Spark Task',
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'Spark Task' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-09T12:26:41.682+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:41.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.037 seconds
[2025-03-09T12:26:43.745+0000] {processor.py:186} INFO - Started process (PID=209) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:43.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:26:43.748+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:43.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:43.754+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:43.753+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job_example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_example.py", line 33, in <module>
    spark_job = SparkSubmitOperator(task_id='Spark Task ',
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'Spark Task ' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-09T12:26:43.755+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:43.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.028 seconds
[2025-03-09T12:26:47.782+0000] {processor.py:186} INFO - Started process (PID=214) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:47.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:26:47.784+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:47.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:47.791+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:47.789+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/spark_job_example.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_job_example.py", line 33, in <module>
    spark_job = SparkSubmitOperator(task_id='Spark Task_1',
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/apache/spark/operators/spark_submit.py", line 137, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 508, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 976, in __init__
    validate_key(self.task_id)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'Spark Task_1' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-03-09T12:26:47.791+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:47.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.026 seconds
[2025-03-09T12:26:48.826+0000] {processor.py:186} INFO - Started process (PID=219) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:48.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:26:48.828+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:48.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:48.836+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:26:49.028+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.028+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG:SparkDag
[2025-03-09T12:26:49.032+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.031+0000] {override.py:1901} INFO - Created Permission View: can edit on DAG:SparkDag
[2025-03-09T12:26:49.033+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.033+0000] {override.py:1901} INFO - Created Permission View: can read on DAG:SparkDag
[2025-03-09T12:26:49.035+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.035+0000] {override.py:1901} INFO - Created Permission View: can delete on DAG Run:SparkDag
[2025-03-09T12:26:49.037+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.037+0000] {override.py:1901} INFO - Created Permission View: menu access on DAG Run:SparkDag
[2025-03-09T12:26:49.039+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.039+0000] {override.py:1901} INFO - Created Permission View: can read on DAG Run:SparkDag
[2025-03-09T12:26:49.041+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.041+0000] {override.py:1901} INFO - Created Permission View: can create on DAG Run:SparkDag
[2025-03-09T12:26:49.041+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:26:49.049+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.049+0000] {dag.py:3262} INFO - Creating ORM DAG for SparkDag
[2025-03-09T12:26:49.056+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:26:49.055+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-08T00:00:00+00:00, run_after=2025-03-09T00:00:00+00:00
[2025-03-09T12:26:49.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.243 seconds
[2025-03-09T12:27:18.268+0000] {processor.py:186} INFO - Started process (PID=180) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:27:18.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:27:18.271+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:27:18.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:27:18.278+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:27:18.284+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:27:18.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:27:18.295+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:27:18.295+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-08T00:00:00+00:00, run_after=2025-03-09T00:00:00+00:00
[2025-03-09T12:27:18.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.041 seconds
[2025-03-09T12:27:48.529+0000] {processor.py:186} INFO - Started process (PID=192) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:27:48.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:27:48.534+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:27:48.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:27:48.545+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:27:48.568+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:27:48.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:27:48.680+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:27:48.680+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-08T00:00:00+00:00, run_after=2025-03-09T00:00:00+00:00
[2025-03-09T12:27:48.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.164 seconds
[2025-03-09T12:28:18.831+0000] {processor.py:186} INFO - Started process (PID=204) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:28:18.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:28:18.835+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:28:18.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:28:18.845+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:28:18.865+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:28:18.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:28:18.954+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:28:18.954+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-08T00:00:00+00:00, run_after=2025-03-09T00:00:00+00:00
[2025-03-09T12:28:18.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.140 seconds
[2025-03-09T12:28:49.116+0000] {processor.py:186} INFO - Started process (PID=468) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:28:49.116+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:28:49.119+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:28:49.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:28:49.136+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:28:49.284+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:28:49.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:28:49.294+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:28:49.293+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:28:49.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.194 seconds
[2025-03-09T12:29:19.599+0000] {processor.py:186} INFO - Started process (PID=612) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:29:19.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:29:19.605+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:29:19.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:29:19.619+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:29:19.779+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:29:19.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:29:19.787+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:29:19.787+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:29:19.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.205 seconds
[2025-03-09T12:29:50.015+0000] {processor.py:186} INFO - Started process (PID=623) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:29:50.016+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:29:50.134+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:29:50.134+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:29:50.138+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:29:50.148+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:29:50.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:29:50.156+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:29:50.156+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:29:50.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.154 seconds
[2025-03-09T12:30:20.580+0000] {processor.py:186} INFO - Started process (PID=635) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:30:20.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:30:20.583+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:30:20.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:30:20.593+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:30:20.611+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:30:20.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:30:20.623+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:30:20.623+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:30:20.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.058 seconds
[2025-03-09T12:30:50.930+0000] {processor.py:186} INFO - Started process (PID=647) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:30:50.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:30:50.934+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:30:50.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:30:50.945+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:30:50.965+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:30:50.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:30:50.977+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:30:50.977+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:30:50.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.062 seconds
[2025-03-09T12:31:21.295+0000] {processor.py:186} INFO - Started process (PID=659) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:31:21.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:31:21.299+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:31:21.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:31:21.309+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:31:21.328+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:31:21.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:31:21.340+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:31:21.340+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:31:21.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.060 seconds
[2025-03-09T12:31:51.601+0000] {processor.py:186} INFO - Started process (PID=671) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:31:51.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:31:51.605+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:31:51.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:31:51.617+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:31:51.637+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:31:51.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:31:51.649+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:31:51.649+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:31:51.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.064 seconds
[2025-03-09T12:32:21.926+0000] {processor.py:186} INFO - Started process (PID=683) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:32:21.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:32:21.930+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:32:21.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:32:21.940+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:32:21.959+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:32:21.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:32:21.971+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:32:21.971+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:32:21.979+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.061 seconds
[2025-03-09T12:32:52.296+0000] {processor.py:186} INFO - Started process (PID=695) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:32:52.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:32:52.300+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:32:52.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:32:52.310+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:32:52.330+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:32:52.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:32:52.344+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:32:52.343+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:32:52.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.063 seconds
[2025-03-09T12:33:22.692+0000] {processor.py:186} INFO - Started process (PID=707) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:33:22.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:33:22.695+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:33:22.695+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:33:22.706+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:33:22.727+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:33:22.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:33:22.740+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:33:22.739+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:33:22.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.062 seconds
[2025-03-09T12:33:53.076+0000] {processor.py:186} INFO - Started process (PID=719) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:33:53.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:33:53.080+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:33:53.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:33:53.089+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:33:53.111+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:33:53.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:33:53.126+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:33:53.126+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:33:53.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.065 seconds
[2025-03-09T12:34:23.413+0000] {processor.py:186} INFO - Started process (PID=738) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:34:23.414+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:34:23.419+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:34:23.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:34:23.436+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:34:23.466+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:34:23.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:34:23.484+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:34:23.484+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:34:23.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.093 seconds
[2025-03-09T12:34:53.817+0000] {processor.py:186} INFO - Started process (PID=750) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:34:53.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:34:53.821+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:34:53.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:34:53.830+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:34:53.848+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:34:53.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:34:53.860+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:34:53.860+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:34:53.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.058 seconds
[2025-03-09T12:35:24.172+0000] {processor.py:186} INFO - Started process (PID=762) to work on /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:35:24.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/spark_job_example.py for tasks to queue
[2025-03-09T12:35:24.176+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:35:24.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:35:24.187+0000] {processor.py:925} INFO - DAG(s) 'SparkDag' retrieved from /opt/airflow/dags/spark_job_example.py
[2025-03-09T12:35:24.209+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:35:24.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-03-09T12:35:24.225+0000] {logging_mixin.py:190} INFO - [2025-03-09T12:35:24.225+0000] {dag.py:4180} INFO - Setting next_dagrun for SparkDag to 2025-03-09T00:00:00+00:00, run_after=2025-03-10T00:00:00+00:00
[2025-03-09T12:35:24.236+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/spark_job_example.py took 0.070 seconds
